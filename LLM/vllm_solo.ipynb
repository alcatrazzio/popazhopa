{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4531f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import base64\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from vllm import LLM, SamplingParams\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc71836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    global SEED\n",
    "    SEED = seed\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(322)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e31abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(text: str) -> str:\n",
    "    pattern = r\"FINAL\\s*ANSWER\\s*:\\s*([A-Z]+)\"\n",
    "    match = re.search(pattern, text.strip(), re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).upper()\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7363ae2",
   "metadata": {},
   "source": [
    "**Qwen 4B:**\n",
    "\n",
    "1) Qwen/Qwen3-4B-Instruct-2507 (8 GB)\n",
    "2) Qwen/Qwen3-4B-Thinking-2507 (8 GB)\n",
    "\n",
    "**Qwen 8B:**\n",
    "\n",
    "1) Qwen/Qwen3-8B (16 GB)\n",
    "\n",
    "**For math:**\n",
    "\n",
    "1) nvidia/OpenMath-Nemotron-7B (15 GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6eefbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544298e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(\n",
    "    model=MODEL_PATH,\n",
    "    trust_remote_code=True,\n",
    "    tensor_parallel_size=1,\n",
    "    gpu_memory_utilization=0.9,\n",
    "    max_model_len=4096,\n",
    "    seed=SEED,\n",
    "    # allowed_local_media_path=os.path.abspath('images'), # FOR VLM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27579226",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(\n",
    "    temperature=0.4,\n",
    "    top_p=0.9,\n",
    "    max_tokens=3600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4751b3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.pickle', \"rb\") as input_file:\n",
    "    model_input = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0128c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "model_output = []\n",
    "\n",
    "prompts = []\n",
    "rids = []\n",
    "\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "for row in tqdm(model_input):\n",
    "    rid = row[\"rid\"]\n",
    "    question = row[\"question\"]\n",
    "    image = Image.open(io.BytesIO(row[\"image\"]))\n",
    "    image_path = f\"images/{rid}.png\"\n",
    "    image.save(image_path)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Choose all the correct options:\\n{question}\\n\\n\n",
    "Write a detailed explanation and the correct answer as a sequence of letters you chose and format it as \n",
    "FINAL ANSWER: <Answer> (example: FINAL ANSWER: AD). Rely only on the information present in the picture.\n",
    "Check every fact very carefully and NEVER invent anything new or not related to the picture.\n",
    "\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                # {\"type\": \"image_url\", \"image_url\": {\"url\": f\"file://{os.path.abspath(image_path)}\"}}, # FOR VLM\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    prompts.append(messages)\n",
    "    rids.append(rid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8b0ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(0, len(prompts), BATCH_SIZE), desc=\"Inference\"):\n",
    "    batch_prompts = prompts[i:i + BATCH_SIZE]\n",
    "    batch_rids = rids[i:i + BATCH_SIZE]\n",
    "\n",
    "    outputs = llm.chat(\n",
    "        messages=batch_prompts,\n",
    "        sampling_params=sampling_params,\n",
    "    )\n",
    "\n",
    "    for rid, output in zip(batch_rids, outputs):\n",
    "        text = output.outputs[0].text\n",
    "        answer_parsed = parse(text)\n",
    "        model_output.append({\"rid\": rid, \"answer\": answer_parsed if answer_parsed else \"B\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3d008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.json', 'w') as output_file:\n",
    "    json.dump(model_output, output_file, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
